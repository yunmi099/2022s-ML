{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunmi099/2022s-ML/blob/main/HW4_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HW4 :: DNN**\n",
        "## 과제 목표\n",
        "* 간단한 Three Layer Network를 구현하기\n",
        "* Pytorch를 사용하여 DNN 구현 후 학습과 테스트하기\n",
        "  \n",
        "  \n",
        "   \n",
        "\n"
      ],
      "metadata": {
        "id": "EXvAS7OZkg_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐  이번 과제는 bb에 코랩 링크, ipynb 파일만 업로드합니다(HW3와 동일하게).   \n",
        "⭐  작성한 코드에 **간단한 주석을 반드시 달아주세요**!  \n",
        "⭐  코딩할 부분을 제외하고는 수정하지 마세요. 수정 시 감점입니다."
      ],
      "metadata": {
        "id": "k5IhqPYwmnUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **문제 1 - Three Layer Network**\n",
        "```class Sigmoid```와 ```Affine```을 구현한 후 이 두 class를 사용하여 ```class ThreeLayerNet```를 완성하세요. \n",
        "* 코드 참고 : deep learning from scratch"
      ],
      "metadata": {
        "id": "OKfJ8-LiFOr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-1\n",
        "class sigmoid의 forward 함수를 구현하세요.  \n",
        "힌트) sigmoid 함수 식"
      ],
      "metadata": {
        "id": "FrrWMAJx6FUC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QSI6QIBkCPWP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.params = []\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      #############################################\n",
        "      ################### 문제 1-1 #################\n",
        "      ############# sigmoid forward 구현 ###########\n",
        "      #############################################\n",
        "        # 한 줄로 구현\n",
        "        result = 1 / (1 + np.exp(-x)) # signoid 함수 식\n",
        "      #############################################\n",
        "      \n",
        "        return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-2\n",
        "class Affine의 forward 함수를 구현하세요.  \n",
        "힌트) affine 함수 식"
      ],
      "metadata": {
        "id": "1YcAkmtN6UXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Affine: # Affine은 Fully Connect를 의미합니다\n",
        "    def __init__(self, W, b):\n",
        "        self.params = [W, b]\n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "      #############################################\n",
        "      ################### 문제 1-2 #################\n",
        "      ############# affine forward 구현 ############\n",
        "      #############################################\n",
        "        # 코드 작성\n",
        "        self.x = x\n",
        "        out = np.dot(x, self.params[0]) + self.params[1] # params list에 있는 W와 b를 내적하여 out에 저장\n",
        "\n",
        "      #############################################\n",
        "      \n",
        "        return out\n"
      ],
      "metadata": {
        "id": "Ds05drVvG5O_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-3\n",
        "\n",
        "  각 layer의 parameter를 ```np.random.randn()``` 를 사용하여 초기화하세요.  \n",
        "  * 조건) ```class ThreeLayerNet```은 총 3개의 fully connected layer로 구성됩니다.\n",
        "  * 힌트) 차원을 잘 고려하세요. \n"
      ],
      "metadata": {
        "id": "aX3vaESK6jp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-4\n",
        "  문제1-1, 2에서 구현한 class를 사용하여 ThreeLayerNet의 layer를 구성하세요.\n",
        "  * 조건) ```class ThreeLayerNet```은 총 3개의 fully connected layer로 구성됩니다.\n",
        "  * 힌트) 차원을 잘 고려하세요."
      ],
      "metadata": {
        "id": "qoPlnkHg_18J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ThreeLayerNet:\n",
        "    def __init__(self, input_size, first_hidden_size, second_hidden_size, output_size):\n",
        "        I, H_1, H_2,O = input_size, first_hidden_size, second_hidden_size, output_size\n",
        "\n",
        "      #############################################\n",
        "      ################### 문제 1-3 #################\n",
        "      ######### parameter initialization ##########\n",
        "      #############################################\n",
        "        self.params = {}\n",
        "        self.params['W1'] = np.random.randn(I, H_1) # 정규분포를 이루는 값을 무작위로 대입\n",
        "        self.params['b1'] = np.zeros(H_1) # 0으로 초기화 \n",
        "        self.params['W2'] = np.random.randn(H_1, H_2) # 정규분포를 이루는 값을 무작위로 대입\n",
        "        self.params['b2'] = np.zeros(H_2) # 0으로 초기화 \n",
        "        self.params['W3'] = np.random.randn(H_2,O) # 정규분포를 이루는 값을 무작위로 대입\n",
        "        self.params['b3'] = np.zeros(O) # 0으로 초기화 \n",
        "      #########################################\n",
        "        \n",
        "\n",
        "        self.layers = [\n",
        "        #############################################\n",
        "        ################### 문제 1-4 #################\n",
        "        ############### stack layers ################\n",
        "        #############################################          \n",
        "            # 코드 작성\n",
        "        Affine(self.params['W1'],self.params['b1']),  Affine(self.params['W2'],self.params['b2']),\n",
        "         Affine(self.params['W3'],self.params['b3']), # (W1,b1), (W2,b2), (W3,b3)를 Affine하여 layers에 저장\n",
        "        #############################################    \n",
        "        ]\n",
        "\n",
        "        # 모든 weight 를 담은 리스트 생성\n",
        "        self.params = []\n",
        "        for layer in self.layers:\n",
        "            self.params += layer.params\n",
        "\n",
        "    def predict(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "VmHw4K5DG3uv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy data로 모델 실행해보기\n",
        "x = np.random.randn(784, 100)\n",
        "model = ThreeLayerNet(100, 50, 30, 10)\n",
        "s = model.predict(x)\n",
        "print(s)"
      ],
      "metadata": {
        "id": "SNI0xGraFAAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ee7263-1bf3-4bd8-d6c8-4db69fb53035"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-170.51270621  268.3811059   326.59103187 ...  -35.89977054\n",
            "  -228.67506738  -88.87043114]\n",
            " [-100.54926358  287.24658482  183.43978009 ... -302.94040698\n",
            "  -466.81737036  415.94038764]\n",
            " [ 206.61083189  203.56367808 -606.14274871 ...  103.29765081\n",
            "    80.44850469  409.52833245]\n",
            " ...\n",
            " [ 679.51934987 -772.25027332  231.75599567 ...  699.71566175\n",
            "   413.69242792  160.82370847]\n",
            " [ 241.00209178  146.12261065  264.49264801 ... -397.6636268\n",
            "    92.71145479 -176.58714572]\n",
            " [ 501.87228715  126.96770563 -406.96644193 ...  300.07330271\n",
            "   338.95696282  169.33452715]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FtZZAx7vovt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문제 2 - Implementing DNN using Pytorch\n",
        "문제 1에서는 Pytorch를 사용하지 않고 DNN을 구현해보았습니다.  \n",
        "문제 2에서는 Pytorch를 사용하여 DNN을 구현하고 MNIST 데이터로 분류 모델 학습을 진행합니다.\n",
        "* 코드 참고: pytorch 공식 튜토리얼"
      ],
      "metadata": {
        "id": "hOzYC0u5GfkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 importing\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "LKcI43VULpeQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Data**"
      ],
      "metadata": {
        "id": "WCbWy3jAMGuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True, # training data\n",
        "    download=True,\n",
        "    transform=ToTensor() # 이미지를 tensor로 변형\n",
        ")\n",
        "\n",
        "# Load test data\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False, # test data\n",
        "    download=True,\n",
        "    transform=ToTensor() # 이미지를 tensor로 변형\n",
        ")\n",
        "\n",
        "# data loader\n",
        "# train, test 각각의 data loader 생성\n",
        "train_loader = torch.utils.data.DataLoader(training_data, batch_size=1, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "D9DqIegtLnz9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check loaded data**\n",
        "train_loader를 사용하여 하나의 데이터를 로드한 후 이 데이터가 어떤 숫자의 데이터인지 이미지로 확인해봅니다."
      ],
      "metadata": {
        "id": "QtJVlNT9A_KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train feature와 label을 train_loader로부터 가져오기\n",
        "train_features, train_labels = next(iter(train_loader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")"
      ],
      "metadata": {
        "id": "IF90dcyJPhVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe35d31-ea05-4b6f-8b0a-0d22e73ec5ee"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([1, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지로 확인\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "00Wypwb2Pr-r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "0d31003d-969a-48ec-c227-1ea867fca6c3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2-1\n",
        "4개의 linear layer와 3개의 ReLU layer를 가진 네트워크를 구성하세요.\n",
        "\n"
      ],
      "metadata": {
        "id": "BB_Qe54pB8_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2-2\n",
        "forward 함수의 빈칸을 구현하세요."
      ],
      "metadata": {
        "id": "mK5ukeeECYJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten() # 28x28 이미지를 784 픽셀 값의 배열로 변경\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            \n",
        "            nn.Linear(in_features=28*28, out_features=512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            #############################################\n",
        "            ################### 문제 2-1 #################\n",
        "            # 4개의 linear layer와 3개의 ReLU layer를 구성하세요\n",
        "            # (위 Linear 포함 4개, ReLU layer 포함 3개를 의미)\n",
        "            #############################################\n",
        "            \n",
        "            # 시작 차원, 끝 차원 잘 고려하여 작성하기\n",
        "            # 중간 차원은 임의로 설정 가능\n",
        "            nn.Linear(512,256), nn.ReLU(),nn.Linear(256,128), nn.ReLU(), \n",
        "            nn.Linear(128,64) # 4개의 linear layer와 3개의 ReLU layer를 구성하여 linear_relu_stack에 저장\n",
        "            #############################################\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #############################################\n",
        "        ################### 문제 2-2 #################\n",
        "        # forward 함수 구현\n",
        "        #############################################\n",
        "        # 코드 작성\n",
        "        x = self.flatten(x) # 다차원의 배열을 1차원 배열로 바꾸어줌\n",
        "\n",
        "        logits = self.linear_relu_stack(x) # linear와 relu layer가 정의 되어있는 stack으로 forwarding했다.\n",
        "\n",
        "        #############################################\n",
        "        return logits # forward 결과 저장"
      ],
      "metadata": {
        "id": "zme9j_4hMiA2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cpu OR gpu 설정\n",
        "# gpu가 있을 경우, device로 cuda를 사용함\n",
        "# colab에서 '런타임 유형 변경'을 하면 gpu 사용할 수 있음\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "kfBLbfwUJgtP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0870f5f0-401d-476f-c961-2c80dffe975a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device) # device로 Network 전송\n",
        "print(model) # 모델 구조 확인"
      ],
      "metadata": {
        "id": "ifGukRqQOUyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0348ae14-3450-409b-8682-5c6ba1171993"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 앞에서 출력해보았던 train_features[0](1개의 데이터)에 대해서 모델 학습 결과 확인해보기\n",
        "logits = model(train_features[0]) # 일부 백그라운드 연산들과 함께 모델의 forward 를 실행 \n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "id": "MdOf0Rd1VEi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4820187f-cda9-47b1-c3b1-5b862b303946"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([56])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train the Network** \n",
        "epoch과 batch를 활용하여 모델을 학습시켜 봅시다."
      ],
      "metadata": {
        "id": "J5G6rO77V7OR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2-3\n",
        "모델의 forward, backward, optimize 하는 부분을 주어진 칸에 구현하세요."
      ],
      "metadata": {
        "id": "n7RwQwKDCjOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)"
      ],
      "metadata": {
        "id": "y7jdCHQphsIO"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter 설정\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # optimizer\n",
        "\n",
        "n_epoch = 3 # the number of epochs\n",
        "n_batch = 32 # the number of batches"
      ],
      "metadata": {
        "id": "XGXKm0pHhnoO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loader 설정하기\n",
        "train_loader = torch.utils.data.DataLoader(training_data, batch_size=n_batch, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=n_batch, shuffle=True)"
      ],
      "metadata": {
        "id": "s3viP29EipLg"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "        # input data 가져오기\n",
        "        # data 는 [inputs, labels]로 구성된 리스트\n",
        "        inputs, labels = data\n",
        "\n",
        "        # optimizer의 파라미터 gradient를 0으로 설정\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #############################################\n",
        "        ################### 문제 2-3 #################\n",
        "        # forward, backward, optimize \n",
        "        ###########################################\n",
        "          # 코드 작성\n",
        "        pred = model(inputs)  # 모델을 forward해 결과값 저장 \n",
        "        loss = criterion(pred,labels) # output과 target의 loss 계산\n",
        "\n",
        "        loss.backward() # backward 함수를 호출해 gradient 계산\n",
        "        optimizer.step() # 모델의 학습 파라미터 갱신\n",
        "        optimizer.zero_grad() #한번의 학습이 완료되면 gradients를 항상 0으로 만든다.\n",
        "        #############################################\n",
        "\n",
        "        # loss 출력\n",
        "        running_loss += loss.item()\n",
        "        if i % n_batch == 0:    # print every n_batch mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / n_batch:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "m6ByMb4whKFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eea760f-b43f-451b-ed73-763e6a5aa1f4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,     1] loss: 0.130\n",
            "[1,    33] loss: 4.152\n",
            "[1,    65] loss: 4.108\n",
            "[1,    97] loss: 4.059\n",
            "[1,   129] loss: 3.999\n",
            "[1,   161] loss: 3.921\n",
            "[1,   193] loss: 3.799\n",
            "[1,   225] loss: 3.565\n",
            "[1,   257] loss: 3.100\n",
            "[1,   289] loss: 2.586\n",
            "[1,   321] loss: 2.361\n",
            "[1,   353] loss: 2.310\n",
            "[1,   385] loss: 2.280\n",
            "[1,   417] loss: 2.260\n",
            "[1,   449] loss: 2.240\n",
            "[1,   481] loss: 2.239\n",
            "[1,   513] loss: 2.220\n",
            "[1,   545] loss: 2.177\n",
            "[1,   577] loss: 2.161\n",
            "[1,   609] loss: 2.130\n",
            "[1,   641] loss: 2.102\n",
            "[1,   673] loss: 2.037\n",
            "[1,   705] loss: 1.968\n",
            "[1,   737] loss: 1.883\n",
            "[1,   769] loss: 1.792\n",
            "[1,   801] loss: 1.709\n",
            "[1,   833] loss: 1.596\n",
            "[1,   865] loss: 1.534\n",
            "[1,   897] loss: 1.395\n",
            "[1,   929] loss: 1.332\n",
            "[1,   961] loss: 1.240\n",
            "[1,   993] loss: 1.168\n",
            "[1,  1025] loss: 1.151\n",
            "[1,  1057] loss: 1.065\n",
            "[1,  1089] loss: 1.038\n",
            "[1,  1121] loss: 0.956\n",
            "[1,  1153] loss: 0.908\n",
            "[1,  1185] loss: 0.898\n",
            "[1,  1217] loss: 0.844\n",
            "[1,  1249] loss: 0.834\n",
            "[1,  1281] loss: 0.775\n",
            "[1,  1313] loss: 0.750\n",
            "[1,  1345] loss: 0.711\n",
            "[1,  1377] loss: 0.766\n",
            "[1,  1409] loss: 0.770\n",
            "[1,  1441] loss: 0.664\n",
            "[1,  1473] loss: 0.686\n",
            "[1,  1505] loss: 0.635\n",
            "[1,  1537] loss: 0.675\n",
            "[1,  1569] loss: 0.618\n",
            "[1,  1601] loss: 0.604\n",
            "[1,  1633] loss: 0.573\n",
            "[1,  1665] loss: 0.560\n",
            "[1,  1697] loss: 0.539\n",
            "[1,  1729] loss: 0.554\n",
            "[1,  1761] loss: 0.526\n",
            "[1,  1793] loss: 0.580\n",
            "[1,  1825] loss: 0.547\n",
            "[1,  1857] loss: 0.502\n",
            "[2,     1] loss: 0.014\n",
            "[2,    33] loss: 0.542\n",
            "[2,    65] loss: 0.512\n",
            "[2,    97] loss: 0.543\n",
            "[2,   129] loss: 0.524\n",
            "[2,   161] loss: 0.514\n",
            "[2,   193] loss: 0.479\n",
            "[2,   225] loss: 0.477\n",
            "[2,   257] loss: 0.523\n",
            "[2,   289] loss: 0.522\n",
            "[2,   321] loss: 0.470\n",
            "[2,   353] loss: 0.494\n",
            "[2,   385] loss: 0.481\n",
            "[2,   417] loss: 0.477\n",
            "[2,   449] loss: 0.442\n",
            "[2,   481] loss: 0.434\n",
            "[2,   513] loss: 0.475\n",
            "[2,   545] loss: 0.448\n",
            "[2,   577] loss: 0.459\n",
            "[2,   609] loss: 0.455\n",
            "[2,   641] loss: 0.488\n",
            "[2,   673] loss: 0.394\n",
            "[2,   705] loss: 0.408\n",
            "[2,   737] loss: 0.420\n",
            "[2,   769] loss: 0.425\n",
            "[2,   801] loss: 0.365\n",
            "[2,   833] loss: 0.427\n",
            "[2,   865] loss: 0.389\n",
            "[2,   897] loss: 0.379\n",
            "[2,   929] loss: 0.458\n",
            "[2,   961] loss: 0.378\n",
            "[2,   993] loss: 0.374\n",
            "[2,  1025] loss: 0.376\n",
            "[2,  1057] loss: 0.375\n",
            "[2,  1089] loss: 0.348\n",
            "[2,  1121] loss: 0.389\n",
            "[2,  1153] loss: 0.360\n",
            "[2,  1185] loss: 0.379\n",
            "[2,  1217] loss: 0.383\n",
            "[2,  1249] loss: 0.372\n",
            "[2,  1281] loss: 0.405\n",
            "[2,  1313] loss: 0.411\n",
            "[2,  1345] loss: 0.322\n",
            "[2,  1377] loss: 0.356\n",
            "[2,  1409] loss: 0.400\n",
            "[2,  1441] loss: 0.411\n",
            "[2,  1473] loss: 0.396\n",
            "[2,  1505] loss: 0.393\n",
            "[2,  1537] loss: 0.385\n",
            "[2,  1569] loss: 0.391\n",
            "[2,  1601] loss: 0.347\n",
            "[2,  1633] loss: 0.327\n",
            "[2,  1665] loss: 0.379\n",
            "[2,  1697] loss: 0.331\n",
            "[2,  1729] loss: 0.343\n",
            "[2,  1761] loss: 0.373\n",
            "[2,  1793] loss: 0.336\n",
            "[2,  1825] loss: 0.331\n",
            "[2,  1857] loss: 0.374\n",
            "[3,     1] loss: 0.009\n",
            "[3,    33] loss: 0.337\n",
            "[3,    65] loss: 0.377\n",
            "[3,    97] loss: 0.348\n",
            "[3,   129] loss: 0.332\n",
            "[3,   161] loss: 0.289\n",
            "[3,   193] loss: 0.384\n",
            "[3,   225] loss: 0.373\n",
            "[3,   257] loss: 0.311\n",
            "[3,   289] loss: 0.345\n",
            "[3,   321] loss: 0.348\n",
            "[3,   353] loss: 0.340\n",
            "[3,   385] loss: 0.322\n",
            "[3,   417] loss: 0.363\n",
            "[3,   449] loss: 0.342\n",
            "[3,   481] loss: 0.342\n",
            "[3,   513] loss: 0.334\n",
            "[3,   545] loss: 0.356\n",
            "[3,   577] loss: 0.296\n",
            "[3,   609] loss: 0.356\n",
            "[3,   641] loss: 0.328\n",
            "[3,   673] loss: 0.288\n",
            "[3,   705] loss: 0.318\n",
            "[3,   737] loss: 0.291\n",
            "[3,   769] loss: 0.300\n",
            "[3,   801] loss: 0.285\n",
            "[3,   833] loss: 0.285\n",
            "[3,   865] loss: 0.304\n",
            "[3,   897] loss: 0.323\n",
            "[3,   929] loss: 0.352\n",
            "[3,   961] loss: 0.294\n",
            "[3,   993] loss: 0.296\n",
            "[3,  1025] loss: 0.336\n",
            "[3,  1057] loss: 0.286\n",
            "[3,  1089] loss: 0.271\n",
            "[3,  1121] loss: 0.308\n",
            "[3,  1153] loss: 0.287\n",
            "[3,  1185] loss: 0.295\n",
            "[3,  1217] loss: 0.268\n",
            "[3,  1249] loss: 0.312\n",
            "[3,  1281] loss: 0.286\n",
            "[3,  1313] loss: 0.264\n",
            "[3,  1345] loss: 0.257\n",
            "[3,  1377] loss: 0.290\n",
            "[3,  1409] loss: 0.262\n",
            "[3,  1441] loss: 0.289\n",
            "[3,  1473] loss: 0.298\n",
            "[3,  1505] loss: 0.312\n",
            "[3,  1537] loss: 0.316\n",
            "[3,  1569] loss: 0.304\n",
            "[3,  1601] loss: 0.279\n",
            "[3,  1633] loss: 0.295\n",
            "[3,  1665] loss: 0.277\n",
            "[3,  1697] loss: 0.326\n",
            "[3,  1729] loss: 0.273\n",
            "[3,  1761] loss: 0.285\n",
            "[3,  1793] loss: 0.296\n",
            "[3,  1825] loss: 0.274\n",
            "[3,  1857] loss: 0.329\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test the Network**"
      ],
      "metadata": {
        "id": "XnqNJjGki4JZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test feature와 label을 test_loader로부터 가져오기\n",
        "test_features, test_labels = next(iter(test_loader))\n",
        "print(f\"Feature batch shape: {test_features.size()}\")\n",
        "print(f\"Labels batch shape: {test_labels.size()}\")"
      ],
      "metadata": {
        "id": "CO1AMDEAjGrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ed000a-2dae-478c-c466-f0c56a32bd29"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([32, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1개 이미지 확인해보기\n",
        "\n",
        "logits = model(test_features[0]) # 일부 백그라운드 연산들과 함께 모델의 forward 를 실행 \n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "\n",
        "\n",
        "img = test_features[0].squeeze()\n",
        "label = test_labels[0]\n",
        "\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Predicted class: {y_pred}\")\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "bgC3vITkjWdU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "1c6d55a4-1c51-479d-f7c7-f20839d93df4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([5])\n",
            "Label: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 test data에 대한 결과 확인\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad(): # 모델을 학습하는 것이 아니므로 gradient 계산을 할 필요가 없음\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "id": "RE_tglcsmmRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fa22c93-0527-495e-ca5c-278f516e4345"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 92 %\n"
          ]
        }
      ]
    }
  ]
}